import pandas as pd
import numpy as np

df=pd.read_csv('income_evaluation.csv')
df

df.columns

for i in df.columns:
    print('unique values of ',i,':', df[i].unique())

df.shape

y=df[' income']
x=df.drop(' income',axis=1)

x.head()

x.columns

y.head()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y=le.fit_transform(y)


y

# scaling numerical values
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

numerical = ['age', ' education-num', ' capital-gain', ' capital-loss', ' hours-per-week']
x[numerical] = scaler.fit_transform(x[numerical])
x.head()

x=pd.get_dummies(x)

x.head(4)



from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)


from sklearn.ensemble import GradientBoostingClassifier
model=GradientBoostingClassifier(n_estimators=500,learning_rate = 0.05,random_state =0)

fit_model=model.fit(x_train,y_train)

y_pred =model.predict(x_test)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
accuracy = accuracy_score(y_test,y_pred)

accuracy

report=classification_report(y_test,y_pred)
print(report)

cm=confusion_matrix(y_test,y_pred)
cm

## hyperparameter tuning

from sklearn.model_selection import GridSearchCV
grid = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':np.arange(100,500,100),}

gb_cv = GridSearchCV(model, grid, cv = 4)
gb_cv.fit(x_train,y_train)

print("Best Parameters:",gb_cv.best_params_)
print("Train Score:",gb_cv.best_score_)
print("Test Score:",gb_cv.score(x_test,y_test))

grid = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':np.arange(100,500,100),'max_depth':[2,3,4,5,6,7] }

gb_cv = GridSearchCV(model, grid, cv = 4)
gb_cv.fit(x_train,y_train)

print("Best Parameters:",gb_cv.best_params_)
print("Train Score:",gb_cv.best_score_)
print("Test Score:",gb_cv.score(x_test,y_test))

